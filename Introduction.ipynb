{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPH7kjUR2m7rc0fZ9ryOTkc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jqc-prof/DL/blob/main/Introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwXFpB5GcX60",
        "outputId": "9ef7731c-a7e8-4047-baa4-719ce8929b90"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  8103.0840,   8103.0840,   8103.0840,   8103.0840,   8103.0840,\n",
              "          8103.0840,   8103.0840,   8103.0840,   2980.9580,   8103.0840,\n",
              "        442413.4062,  59874.1406])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "#generate a matrix of 12 32 float digits 0-11\n",
        "x = torch.arange(12, dtype=torch.float32)\n",
        "x.numel()\n",
        "x.shape\n",
        "X = x.reshape(3,4)\n",
        "\n",
        "#Slicing\n",
        "#Access last row (-1) and rows 1-3\n",
        "X[-1], X[0:3]\n",
        "\n",
        "#Set matrix of 3rd row 3rd column to 13\n",
        "X[2, 2] = 13\n",
        "X\n",
        "\n",
        "#For instance, [:2, :] accesses the first and second rows, where : takes\n",
        "#all the elements along axis 1 (column).\n",
        "X[:2, :] = 9\n",
        "X\n",
        "\n",
        "#turn values into probabilities for classifiers using exp() which is basically\n",
        "#e^xi\n",
        "torch.exp(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#scalar manipulation\n",
        "x = torch.tensor([1.0, 2, 4, 8])\n",
        "y = torch.tensor([2, 2, 2, 2])\n",
        "x + y, x - y, x * y, x / y, x ** y\n",
        "\n",
        "#We can also concatenate multiple tensors, stacking them end-to-end to\n",
        "#form a larger one\n",
        "X2 = torch.arange(12, dtype=torch.float32).reshape((3,4))\n",
        "Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n",
        "\n",
        "#dim=0 stacks them vertically adding more rows torch.cat(((2,3),(3,3)), dim=0)\n",
        "#results in dimensions (5,3) and torch.cat(((2,3),(2,3)), dim=1). (axis0, axis1)\n",
        "#results in (2,6)\n",
        "torch.cat((X2, Y), dim=0), torch.cat((X2, Y), dim=1)\n",
        "\n",
        "#checks to see what indexes of matrix 1 and 2 match\n",
        "X2 == Y\n",
        "#summation\n",
        "X.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AQWnlfpkWGM",
        "outputId": "68196546-ed8d-4f90-b98f-6ee8379aa3eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(256.)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Broadcasting expands one or both arrays by copying elements along axes with\n",
        "#length 1 so that after this transformation, the two tensors have the same shape\n",
        "#then performs elementwise operation on the resulting arrays.\n",
        "#it is meant to multiple vectors of 2 differing lengths.\n",
        "#a = torch.arange(3).reshape((3, -1))\n",
        "#b = torch.arange(2).reshape((-1, 2))\n",
        "\n",
        "a = torch.arange(24).reshape((2,3,4))\n",
        "b = torch.arange(24).reshape((2,3,-1))\n",
        "\n",
        "a, b\n",
        "#produces a 3x2 matrix by replicating matrix a along columns and matrix b along\n",
        "#the rows before adding them elementwise.\n",
        "a+b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8lXa_DOlEEn",
        "outputId": "7a8dfb5e-2197-47e2-e2ed-63787e14a606"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0,  2,  4,  6],\n",
              "         [ 8, 10, 12, 14],\n",
              "         [16, 18, 20, 22]],\n",
              "\n",
              "        [[24, 26, 28, 30],\n",
              "         [32, 34, 36, 38],\n",
              "         [40, 42, 44, 46]]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#memory saving techniques\n",
        "#if we do Y = X + Y, Y becomes allocated to a new position in memory.\n",
        "#It first evaluates X + Y and assigns it to a new location.\n",
        "#id(Y) locates the position of the Y tensor in memory.\n",
        "before = id(Y)\n",
        "Y = Y + X\n",
        "id(Y) == before\n",
        "\n",
        "#we dont want to allocate memory all over the place,\n",
        "#we need to perform these updates in place. it causes an issue where multiple\n",
        "#variables point to the same parameters. update references or cause memory leak\n",
        "\n",
        "#in-place operations can be performed by using slice:\n",
        "Z = torch.zeros_like(Y)\n",
        "print('id(Z): ', id(Z))\n",
        "Z[:] = X + Y\n",
        "print('id(Z): ', id(Z))\n",
        "\n",
        "#If X is not reused in subsequent computations we can also use X[:] = X + Y\n",
        "#or X += Y to reduce memory overhead of the operation\n",
        "before = id(X)\n",
        "X += Y\n",
        "id(X) == before"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cltw1_5KYbu6",
        "outputId": "9eed8cb8-4d30-4cec-fbde-77f174aad205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id(Z):  135477633441936\n",
            "id(Z):  135477633441936\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tensor/matrix generation\n",
        "torch.zeros((2,3,4))\n",
        "torch.ones((2,3,4))\n",
        "#The following snippet creates\n",
        "#a tensor with elements drawn from a standard Gaussian (normal)\n",
        "#distribution with mean 0 and standard deviation 1.\n",
        "torch.randn(3,4)\n",
        "torch.tensor([[2,1,4,3],[1,2,3,4],[4,3,2,1]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnXRHFDNrStd",
        "outputId": "2f34adc5-4a9d-42e3-b59a-322080247357"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2, 1, 4, 3],\n",
              "        [1, 2, 3, 4],\n",
              "        [4, 3, 2, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Object conversion\n",
        "#Conversion to a NumPy tensor (ndarray)\n",
        "#The torch tensor and NumPy array will share their underlying memory,\n",
        "#and changing one through an in-place operation will also change the other.\n",
        "A = X.numpy()\n",
        "B = torch.from_numpy(A)\n",
        "type(A), type(B)\n",
        "#conversion\n",
        "a = torch.tensor([3.5])\n",
        "a, a.item(), float(a), int(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AmndeKqZAnM",
        "outputId": "eb592c69-f0f5-4af2-9dc3-4c2775c0b1ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([3.5000]), 3.5, 3.5, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ]
}